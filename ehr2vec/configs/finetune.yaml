env: local
paths:
  data_path: "../outputs/data_icd10"
  model_path: "outputs/pretraining/behrt_test"
  checkpoint_epoch: 2
  outcome: "../outputs/data_icd10/outcomes/TEST_CENSOR/TEST_CENSOR.pt"
  # censor: "outputs/outcomes/TEST/TEST.pt"
  #output_path: "outputs/finetuning"
  run_name: "test"
  tokenized_dir: "tokenized"
  tokenized_file: "tokenized_val.pt"
  tokenized_pids: "pids_val.pt"

model:
  pool_type: "mean"
  behrt_embeddings: true

data:
  num_patients: null #300
  val_split: 0.2
  truncation_len: 30
  select_censored: false
  # gender: M
  min_age: 0
  max_age: 100
  # min_len: null
  #code_types:
   # - D
  min_len: 2

outcome: 
  type: TEST_OUTCOME
  n_hours: -100 # censor time
  censor_type: TEST_OUTCOME

trainer_args:
  sampler: true
  sample_weight: .1 # adjust the sampling weight of the positive class (1 is balanced)
  pos_weight: null # weight for positive class in the loss
  batch_size: 8
  val_batch_size: 32
  effective_batch_size: 16
  epochs: 2
  info: true
  gradient_clip: 
    clip_value: 1.0
  mixed_precision: false
  shuffle: true
  
optimizer:
  lr: 5e-4
  eps: 1e-6

scheduler:
  _target_: transformers.get_constant_schedule_with_warmup
  num_warmup_steps: 10
  #num_training_steps: 100

metrics:
  accuracy:
    _target_: evaluation.metrics.Accuracy
    threshold: 0.6
  balanced_accuracy:
    _target_: evaluation.metrics.Balanced_Accuracy
  precision:
    _target_: evaluation.metrics.Precision
  recall:
    _target_: evaluation.metrics.Recall
  roc_auc:
    _target_: evaluation.metrics.ROC_AUC
  pr_auc:
    _target_: evaluation.metrics.PR_AUC
  f1:
    _target_: evaluation.metrics.F1
  precentage_positives:
    _target_: evaluation.metrics.Percentage_Positives
  mean_probability:
    _target_: evaluation.metrics.Mean_Probability
  cohen_kappa:
    _target_: evaluation.metrics.Cohen_Kappa
  mathews_correlation:
    _target_: evaluation.metrics.Matthews_Correlation_Coefficient
  true_positives:
    _target_: evaluation.metrics.True_Positives
  true_negatives:
    _target_: evaluation.metrics.True_Negatives
  false_positives:
    _target_: evaluation.metrics.False_Positives
  false_negatives:
    _target_: evaluation.metrics.False_Negatives
  
  
 
